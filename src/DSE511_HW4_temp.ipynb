{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c363a7",
   "metadata": {},
   "source": [
    "\n",
    "# DSE511 — Homework #4: Sorting, Data Structures, and Big‑O\n",
    "\n",
    "**Instructor:** Scott Emrich  \n",
    "**Course:** DSE 511 – Fall 2025  \n",
    "**Starter Notebook Generated:** 2025-09-10 16:29:27\n",
    "\n",
    "---\n",
    "\n",
    "## How to use this notebook\n",
    "- Run each cell in order. Fill in any **TODO** sections.\n",
    "- Keep your code **well‑commented** and your plots clearly labeled.\n",
    "- For reproducibility, set the random seed as shown below.\n",
    "- When you're done, export both the `.ipynb` and an `.html` of this notebook and submit on Canvas.\n",
    "\n",
    "> **Reminder:** When making charts, use **matplotlib**, give each chart its **own figure** (no subplots), and **do not set explicit colors** unless instructed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a5cd53",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "rng = np.random.default_rng(seed=511)\n",
    "random.seed(511)\n",
    "\n",
    "# Timing and plotting\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility: timing helper\n",
    "def time_function(fn, *args, repeat=5, **kwargs):\n",
    "    \"\"\"Return the best of `repeat` wall-clock timings for fn(*args, **kwargs).\"\"\"\n",
    "    best = float('inf')\n",
    "    result = None\n",
    "    for _ in range(repeat):\n",
    "        start = time.perf_counter()\n",
    "        out = fn(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        if elapsed < best:\n",
    "            best = elapsed\n",
    "            result = out\n",
    "    return best, result\n",
    "\n",
    "print(\"Environment ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb370f",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part A — Sorting Showdown\n",
    "\n",
    "**Goal:** Empirically compare sorting algorithms and relate runtime to big‑O.\n",
    "\n",
    "You will:\n",
    "1. Generate integer arrays of increasing size.\n",
    "2. Sort using:\n",
    "   - Python built‑in `sorted()` (Time to sort ~ O(n log n) average/worst on random data)\n",
    "   - Your own **insertion sort** (O(n²))\n",
    "   - One additional algorithm of your choice (e.g., `numpy.sort`); must add\n",
    "3. Measure wall‑clock runtimes as `n` grows.\n",
    "4. Plot runtime vs `n` and discuss alignment with theory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement insertion sort (in-place or return a new list)\n",
    "def insertion_sort(arr):\n",
    "    a = list(arr)\n",
    "    \n",
    "    #fill in; this version will return a new list using the temp variable a\n",
    "    \n",
    "    return a\n",
    "\n",
    "# Sanity check\n",
    "sample = [5, 2, 4, 6, 1, 3]\n",
    "assert insertion_sort(sample) == sorted(sample)\n",
    "print(\"Insertion sort sanity check passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86836f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Experiment sizes (adjust if runtime too long or too short); you can also add more data points\n",
    "sizes = [5_000, 10_000, 20_000]\n",
    "repeat = 3\n",
    "\n",
    "# Cap insertion sort at manageable n\n",
    "ins_cap = 20_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {\n",
    "    'n': [],\n",
    "    'sorted_builtin': [],\n",
    "    'insertion_sort': [],\n",
    "    'numpy_sort': []  # TODO; must include below or change to another sort\n",
    "}\n",
    "\n",
    "for n in sizes:\n",
    "    data = rng.integers(low=0, high=10_000_000, size=n, dtype=np.int64)\n",
    "    \n",
    "    t_sorted, _ = time_function(sorted, data, repeat=repeat)\n",
    "    # using library similar, could be t_numpy, _ = ... and then your would add to results below\n",
    "    \n",
    "    if n <= ins_cap:\n",
    "        t_insert, _ = time_function(insertion_sort, data, repeat=repeat)\n",
    "    else:\n",
    "        t_insert = np.nan\n",
    "    \n",
    "    results['n'].append(n)\n",
    "    results['sorted_builtin'].append(t_sorted)\n",
    "    results['insertion_sort'].append(t_insert)\n",
    "\n",
    "import pandas as pd\n",
    "dfA = pd.DataFrame(results)\n",
    "dfA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be50b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO; plot linear plot from results using the log log template to help.  Need two plots for full credit\n",
    "\n",
    "plt.figure()\n",
    "for key in ['sorted_builtin', 'numpy_sort', 'insertion_sort']:\n",
    "    plt.plot(dfA['n'], dfA[key], marker='o', label=key)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('n (log)')\n",
    "plt.ylabel('Runtime (s, log)')\n",
    "plt.title('Sorting runtime vs n (log-log)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101f663",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part B — Data Structures in Action: Membership Testing\n",
    "\n",
    "**Goal:** Compare membership query performance for `list` (≈ O(n)), `set` (≈ O(1) average), and `dict` (≈ O(1) average).\n",
    "\n",
    "You will:\n",
    "1. Build collections of increasing size of unique IDs/strings.\n",
    "2. Generate random queries that are both present and absent.\n",
    "3. Measure membership test times (`x in structure`) for each structure type.\n",
    "4. Plot how query time scales with `n`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sizes_B = [10_000, 100_000, 500_000]\n",
    "queries_per_size = 1_000\n",
    "\n",
    "def gen_ids(n):\n",
    "    ids = [f\"id_{i:07d}\" for i in range(n)]\n",
    "    rng.shuffle(ids)\n",
    "    return ids\n",
    "\n",
    "def membership_timing(ids, structure_type='list'):\n",
    "    if structure_type == 'list':\n",
    "        coll = list(ids)\n",
    "        def contains(x): return x in coll\n",
    "    elif structure_type == 'set':\n",
    "        coll = set(ids)\n",
    "        def contains(x): return x in coll\n",
    "    elif structure_type == 'dict':\n",
    "        coll = {x: True for x in ids}\n",
    "        def contains(x): return x in coll\n",
    "    \n",
    "    present = rng.choice(ids, size=queries_per_size//2, replace=False)\n",
    "    absent = [f\"nope_{i:07d}\" for i in range(queries_per_size - len(present))]\n",
    "    queries = np.concatenate([present, absent])\n",
    "    rng.shuffle(queries)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    for q in queries:\n",
    "        _ = contains(q)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return elapsed\n",
    "\n",
    "records = {'n': [], 'structure': [], 'time_s': []}\n",
    "\n",
    "for n in sizes_B:\n",
    "    ids = gen_ids(n)\n",
    "    for stype in ['list', 'set', 'dict']:\n",
    "        t = membership_timing(ids, structure_type=stype)\n",
    "        records['n'].append(n)\n",
    "        records['structure'].append(stype)\n",
    "        records['time_s'].append(t)\n",
    "\n",
    "dfB = pd.DataFrame(records)\n",
    "dfB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072686f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "for stype in ['list', 'set', 'dict']:\n",
    "    sub = dfB[dfB['structure'] == stype]\n",
    "    plt.plot(sub['n'], sub['time_s'], marker='o', label=stype)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Total time for membership queries (s)')\n",
    "plt.title('Membership testing time vs n')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f04a59",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part C — Reflection\n",
    "\n",
    "In 1–2 pages, discuss:\n",
    "- How well did your empirical results align with expected big‑O?\n",
    "- What practical advice would you give a teammate choosing data structures and sorting methods?\n",
    "- Were there any surprises in your experiments? Explain.\n",
    "- How did you ensure reproducibility?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f54d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
